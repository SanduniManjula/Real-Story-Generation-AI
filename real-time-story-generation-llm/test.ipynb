{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01190954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramFiles\\anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\ProgramFiles\\anaconda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "d:\\ProgramFiles\\anaconda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "d:\\ProgramFiles\\anaconda\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\ProgramFiles\\anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Once upon a time in a distant kingdom, there was a young princess who was gifted with magical powers. She was said to be able to fly, teleport and summon monsters from other worlds. One day, she found herself in a war torn land where she met a young wizard and together they discovered a way to defeat the dragon and save the princess. They also found out that she possessed a powerful magic that could manipulate the magic of dragons, giving them the ability to destroy the world in a single blow. It wasn't long before the wizard revealed that he was one of the few who could control the power of the dragons, and he would be the first to turn her into a dragon. After the princess was transformed into a dragon, she was then released from her prison and discovered that the wizard had trapped her in his tower. She fought her way through the castle until she reached the wizard. The wizard told her that he would leave her behind if she would not swear a vow of non-interference in his plans. The princess would have no choice but to fulfill his vow and pledge her loyalty to the wizard, giving him a powerful magical sword. She then left her prison and took the sword with her to the wizard's tower to fight the dragon. She defeated the dragon and the wizard was freed from his prison. The princess and the wizard would become close friends and the two would soon begin a romantic relationship. The wizard's love for the princess was so strong that the wizard eventually ended his\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Model and tokenizer\n",
    "MODEL_NAME = \"gpt2-medium\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Prompt to start the story\n",
    "prompt = \"Once upon a time in a distant kingdom, there was a young princess who\"\n",
    "\n",
    "# Encode the prompt\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate text\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_length=300,          # length of the story\n",
    "    do_sample=True,          # sample instead of greedy decoding\n",
    "    temperature=0.8,         # creativity level\n",
    "    top_k=50,                # top-k sampling\n",
    "    top_p=0.95,              # nucleus sampling\n",
    "    num_return_sequences=1   # how many stories you want\n",
    ")\n",
    "\n",
    "# Decode and print\n",
    "story = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(story)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
